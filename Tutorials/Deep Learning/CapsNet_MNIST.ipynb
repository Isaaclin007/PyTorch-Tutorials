{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CapsNet-MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFE7Ywt3T74J",
        "colab_type": "text"
      },
      "source": [
        "<center><h1> Capsule Networks for Digit Recognition in PyTorch</h1></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMojBAyvUIQy",
        "colab_type": "text"
      },
      "source": [
        "We are going to implement the Capsule Network from Prof. Hinton's paper on [Dynamic Routing Between Capsules](https://arxiv.org/pdf/1710.09829.pdf). The network consists of the novel Primary and Digit Caps Layers which perform nested convolutions. Dynamic routing, or more specifically Routing by Agreement, takes place in the Digit Caps Capsule Layer which we will discuss in more detail. So let's get started and begin with or standard imports from the PyTorch module. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkLj5BF5VsnD",
        "colab_type": "text"
      },
      "source": [
        "## 1. Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4a6LqqHT34G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import dependencies\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Use GPU\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if use_cuda else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c1M3OLTVrS7",
        "colab_type": "text"
      },
      "source": [
        "## 2. Define the Squash Function\n",
        "\n",
        "Caspule layers make use of a different squashing non-linearity than softmax and sigmoid. This function is called the squash function. This enables us to represent the length of the outut vector from the capsule as a probability. This probability indicates the presence of entity represented by capsule in the input. The squashing function can be mathematically expressed as-\n",
        "\n",
        "<center> $v_{j} = \\frac{||s_{j}^{2}||}{||1 + s_{j}^{2}||} \\frac{s_{j}}{||s_{j}||}$</center>\n",
        "\n",
        "Here, $v_{j}$ is the vector output from the capsule and $s_{j}$ is its total input. For all but the first layer capsules, The total input is the weighted sum of all the prediction vectors $\\hat{u}_{j|i}$ from all the capsule layers in the layer below. This can be mathematically expressed as-\n",
        "<center>$s_{j} = \\sum_{i}c_{ij}\\hat{u}_{j|i}$</center>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_nc5SacXYo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def squash(x):\n",
        "    lengths2 = x.pow(2).sum(dim=2)\n",
        "    lengths = lengths2.sqrt()\n",
        "    x = x * (lengths2 / (1 + lengths2) / lengths).view(x.size(0), x.size(1), 1)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0lnE9H3YWjN",
        "colab_type": "text"
      },
      "source": [
        "## 3. Routing Mechanism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGa5APeuYcBd",
        "colab_type": "text"
      },
      "source": [
        "The dynamic routing mechanism is implemented between capsule layers and works on the basis of routing softmax, whose inputs are initial logits $b_{ij}$. These are the log probabilities that capsule i should be coupled to capsule j. \n",
        "\n",
        "<center>$ c_{ij} = \\frac{exp(b_{ij})}{\\sum_{k}exp(b_{ik})}$</center>\n",
        "\n",
        "Now, the agreement between two capsule layers is simply defined as $a_{ij} = v_{j}.\\hat{u}_{j|i}$. This agreement is treated as if it was a log\n",
        "likelihood and is added to the initial logit, $b_{ij}$ before computing the new values for all the coupling coefficients linking capsule i to higher level capsules.\n",
        "\n",
        "In convolutional capsule layers, each capsule outputs a local grid of vectors to each type of capsule in the layer above using different transformation matrices for each member of the grid as well as for\n",
        "each type of capsule.\n",
        "\n",
        "The main idea here is that the iterative process is repeated for a fixed number of times. Once the capsule j corresponding to capsule i is determined with maximum agreement, information is passed to capsule j. In order to understand the algorithm completely, you are encouraged to read the paper. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE3tDzA-YVx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AgreementRouting(nn.Module):\n",
        "    def __init__(self, input_caps, output_caps, n_iterations):\n",
        "        super(AgreementRouting, self).__init__()\n",
        "        self.n_iterations = n_iterations\n",
        "        self.b = nn.Parameter(torch.zeros((input_caps, output_caps)))\n",
        "    \n",
        "    def forward(self, u_predict):\n",
        "        batch_size, input_caps, output_caps, output_dim = u_predict.size()\n",
        "\n",
        "        c = F.softmax(self.b) #softmax routing\n",
        "        s = (c.unsqueeze(2) * u_predict).sum(dim=1)\n",
        "        v = squash(s)\n",
        "\n",
        "        #iterate over capsules for a fixed number of iterations\n",
        "        if self.n_iterations > 0:\n",
        "            b_batch = self.b.expand((batch_size, input_caps, output_caps))\n",
        "            for r in range(self.n_iterations):\n",
        "                v = v.unsqueeze(1)\n",
        "                b_batch = b_batch + (u_predict * v).sum(-1)\n",
        "\n",
        "                c = F.softmax(b_batch.view(-1, output_caps)).view(-1, input_caps, output_caps, 1)\n",
        "                s = (c * u_predict).sum(dim=1)\n",
        "                v = squash(s)\n",
        "\n",
        "        return v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yQOTR6YbA2b",
        "colab_type": "text"
      },
      "source": [
        "## 4. Capsule Layer\n",
        "\n",
        "We will now construct the Capsule layer. This is the layer wherein the routing takes place. Prediction $\\hat{u}_{j|i}$ is obtained from the previous layer, reshaped and passed to the routing mechanism. \n",
        "\n",
        "Input to the Capsule layer is the squashed 3 dimensional array obtained from the previous Capsule layer which we will discuss in the next section. The routing mechanism in the Capsule layer returns the output capsule vector v."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BADW2eeAa_us",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CapsLayer(nn.Module):\n",
        "    def __init__(self, input_caps, input_dim, output_caps, output_dim, routing_module):\n",
        "        super(CapsLayer, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.input_caps = input_caps\n",
        "        self.output_dim = output_dim\n",
        "        self.output_caps = output_caps\n",
        "        self.weights = nn.Parameter(torch.Tensor(input_caps, input_dim, output_caps * output_dim))\n",
        "        self.routing_module = routing_module\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.input_caps)\n",
        "        self.weights.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, caps_output):\n",
        "        caps_output = caps_output.unsqueeze(2)\n",
        "        u_predict = caps_output.matmul(self.weights)\n",
        "        u_predict = u_predict.view(u_predict.size(0), self.input_caps, self.output_caps, self.output_dim)\n",
        "        v = self.routing_module(u_predict)\n",
        "        return v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kA8Uf0qbpm4",
        "colab_type": "text"
      },
      "source": [
        "## 5. Primary Capsule Layer\n",
        "\n",
        "The primary capsule layer, also known as PrimaryCaps layer, is the first layer consisting of nested convolutions. The layer is followed by a convolution layer at the input. The layer then links to the main Capsule layer. \n",
        "\n",
        "Output to the primary capsule layer is a 3 dimensional vector $[batch\\_size,out\\_caps,out\\_dim]$ wherein 'out_caps' is the output capsules, i.e- the number of capsules in the next layer and 'out_dim' is the dimension of output capsules. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVDLDBn0buLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PrimaryCapsLayer(nn.Module):\n",
        "    def __init__(self, input_channels, output_caps, output_dim, kernel_size, stride):\n",
        "        super(PrimaryCapsLayer, self).__init__()\n",
        "        self.conv = nn.Conv2d(input_channels, output_caps * output_dim, kernel_size=kernel_size, stride=stride)\n",
        "        self.input_channels = input_channels\n",
        "        self.output_caps = output_caps\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def forward(self, input):\n",
        "        out = self.conv(input)\n",
        "        N, C, H, W = out.size()\n",
        "        out = out.view(N, self.output_caps, self.output_dim, H, W)\n",
        "\n",
        "        # will output N x OUT_CAPS x OUT_DIM\n",
        "        out = out.permute(0, 1, 3, 4, 2).contiguous()\n",
        "        out = out.view(out.size(0), -1, out.size(4))\n",
        "        out = squash(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajRT0rFxdCZx",
        "colab_type": "text"
      },
      "source": [
        "## 6. Assemble Layers to construct the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwFSxrg6dKFq",
        "colab_type": "text"
      },
      "source": [
        "And here we are! Now we can assemble all our layers in the correct order to construc the Capsule Network. Starting from the top-  \n",
        "$\\rightarrow$A 2d convolution layer, $Conv2d$.  \n",
        "\n",
        "$\\rightarrow$The primary Capsule Layer, $PrimaryCapsLayer$ with its arguments as $input\\_channels, output\\_caps, output\\_dim, kernel\\_size, stride$.  \n",
        "\n",
        "$\\rightarrow$The Capsule Layer, $CapsLayer$ with the arguments $input\\_caps, input\\_dim, output\\_caps, output\\_dim, routing\\_module$. This is the layer where the routing takes place, i.e- set the argument $routing\\_module$ to $'Agreement Routing'$ which takes in the arguments $num\\_primaryCaps, n\\_classes, routing\\_iterations$.  \n",
        "\n",
        "$\\rightarrow$Fully-connected layers using $Linear$ with ReLU and Sigmoid activations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGUJxNaDdIzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CapsNet(nn.Module):\n",
        "    def __init__(self, routing_iterations, n_classes=10):\n",
        "        super(CapsNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 256, kernel_size=9, stride=1)\n",
        "        self.primaryCaps = PrimaryCapsLayer(256, 32, 8, kernel_size=9, stride=2)  # outputs 6*6\n",
        "        self.num_primaryCaps = 32 * 6 * 6\n",
        "        routing_module = AgreementRouting(self.num_primaryCaps, n_classes, routing_iterations)\n",
        "        self.digitCaps = CapsLayer(self.num_primaryCaps, 8, n_classes, 16, routing_module)\n",
        "        # self.flatten = nn.Flatten()\n",
        "        # self.fc1 = nn.Linear(n_dim * n_classes, 512)\n",
        "        # self.fc2 = nn.Linear(512, 1024)\n",
        "        # self.fc3 = nn.Linear(1024,784)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.conv1(input)\n",
        "        x = F.relu(x)\n",
        "        x = self.primaryCaps(x)\n",
        "        x = self.digitCaps(x)\n",
        "        probs = x.pow(2).sum(dim=2).sqrt()\n",
        "        # x = self.flatten(x)\n",
        "        # x = F.relu(self.fc1(x))\n",
        "        # x = F.relu(self.fc2(x))\n",
        "        # x = F.sigmoid(self.fc3(x))\n",
        "        return x, probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE1vbnrefKsV",
        "colab_type": "text"
      },
      "source": [
        "## 7. Initialize Margin Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2xjyvyCfTQD",
        "colab_type": "text"
      },
      "source": [
        "We deviate from our standard loss metrics for this tutorial and try out a new loss function called the Margin Loss. The reason behind this is that we wish to assess the capsule vector instantiation corresponding to eah digit. This is because we are using the length of the instantiation vector to represent the probability that a capule's entity exists. Thus, we would like to the top level capsule for digit class 'k' to have higher instantiation if the digit is present in the image.  \n",
        "\n",
        "Margin Loss can be mathematically expressed as-  \n",
        "<center>$L_{k} = T_{k} max(0,m^{+} - ||v_{k}||)^{2} + \\lambda(1 - T_{k})max(0,||v_{k}|| - m^{-})^{2}$ </center>\n",
        "\n",
        "\n",
        "Here, $T_{k} = 1$ if a digit of class 'k' is present, $m^{+} = 0.9$ and $m^{-} = 0.1$. $\\lambda$ is used as a donw-weighting constant of the loss for absent digit classes This stops the initial learning from shrinking the lengths of activity vectors of all digit capsules.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr3az5yEfSgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MarginLoss(nn.Module):\n",
        "    def __init__(self, m_pos, m_neg, lambda_):\n",
        "        super(MarginLoss, self).__init__()\n",
        "        self.m_pos = m_pos\n",
        "        self.m_neg = m_neg\n",
        "        self.lambda_ = lambda_\n",
        "\n",
        "    def forward(self, lengths, targets, size_average=True):\n",
        "        t = torch.zeros(lengths.size()).long()\n",
        "        if targets.is_cuda:\n",
        "            t = t.cuda()\n",
        "        t = t.scatter_(1, targets.data.view(-1, 1), 1)\n",
        "        targets = Variable(t)\n",
        "        losses = targets.float() * F.relu(self.m_pos - lengths).pow(2) + \\\n",
        "                 self.lambda_ * (1. - targets.float()) * F.relu(lengths - self.m_neg).pow(2)\n",
        "        return losses.mean() if size_average else losses.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8GN1GUIhn-1",
        "colab_type": "text"
      },
      "source": [
        "## 8. Train and Test the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbamkX_thw7S",
        "colab_type": "text"
      },
      "source": [
        "All right, now we are all setup to start training our CapsNet. We can load the MNIST dataset from PyTorch and load the data in the 'DataLoader' (as we did in the previous tutorials). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNKMyGRphnLn",
        "colab_type": "code",
        "outputId": "6572d12f-ed1d-4080-fd69-471dfae764bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "batch_size = 128\n",
        "test_batch_size = 100\n",
        "epochs = 10\n",
        "routing_iterations = 3\n",
        "lr = 0.001\n",
        "loss_train = []\n",
        "loss_test = []\n",
        "\n",
        "#Load training data\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.Pad(2), transforms.RandomCrop(28),\n",
        "                        transforms.ToTensor()\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#Load testing data\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])),\n",
        "    batch_size=test_batch_size, shuffle=False)\n",
        "\n",
        "#Initialize model and training paramters\n",
        "model = CapsNet(routing_iterations).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=15, min_lr=1e-6)\n",
        "loss_fn = MarginLoss(0.9, 0.1, 0.5)\n",
        "\n",
        "#Train the model\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data).to(device), Variable(target, requires_grad=False).to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output, probs = model(data)\n",
        "        loss = loss_fn(probs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % batch_size == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                        100. * batch_idx / len(train_loader), loss.item()))\n",
        "        loss_train.append(loss.item())\n",
        "        \n",
        "#Test the model\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        output, probs = model(data)\n",
        "        test_loss += loss_fn(probs, target, size_average=False).item()\n",
        "\n",
        "        pred = probs.data.max(1, keepdim=True)[1]  # get the index of the max probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    return test_loss\n",
        "\n",
        "#Iterate over epochs\n",
        "for epoch in range(1, epochs + 1):\n",
        "        train(epoch)\n",
        "        test_loss = test()\n",
        "        loss_test.append(test_loss)\n",
        "        scheduler.step(test_loss)\n",
        "        torch.save(model.state_dict(),\n",
        "                   '{:03d}_model_dict_{}.pth'.format(epoch, routing_iterations))\n",
        "        "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.080879\n",
            "Train Epoch: 1 [16384/60000 (27%)]\tLoss: 0.006140\n",
            "Train Epoch: 1 [32768/60000 (55%)]\tLoss: 0.005142\n",
            "Train Epoch: 1 [49152/60000 (82%)]\tLoss: 0.001950\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0244, Accuracy: 9839/10000 (98%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.003473\n",
            "Train Epoch: 2 [16384/60000 (27%)]\tLoss: 0.002214\n",
            "Train Epoch: 2 [32768/60000 (55%)]\tLoss: 0.001916\n",
            "Train Epoch: 2 [49152/60000 (82%)]\tLoss: 0.002433\n",
            "\n",
            "Test set: Average loss: 0.0170, Accuracy: 9898/10000 (99%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.002062\n",
            "Train Epoch: 3 [16384/60000 (27%)]\tLoss: 0.001276\n",
            "Train Epoch: 3 [32768/60000 (55%)]\tLoss: 0.001528\n",
            "Train Epoch: 3 [49152/60000 (82%)]\tLoss: 0.001160\n",
            "\n",
            "Test set: Average loss: 0.0095, Accuracy: 9932/10000 (99%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.001378\n",
            "Train Epoch: 4 [16384/60000 (27%)]\tLoss: 0.001322\n",
            "Train Epoch: 4 [32768/60000 (55%)]\tLoss: 0.002625\n",
            "Train Epoch: 4 [49152/60000 (82%)]\tLoss: 0.001617\n",
            "\n",
            "Test set: Average loss: 0.0116, Accuracy: 9921/10000 (99%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.001244\n",
            "Train Epoch: 5 [16384/60000 (27%)]\tLoss: 0.002248\n",
            "Train Epoch: 5 [32768/60000 (55%)]\tLoss: 0.000965\n",
            "Train Epoch: 5 [49152/60000 (82%)]\tLoss: 0.000983\n",
            "\n",
            "Test set: Average loss: 0.0100, Accuracy: 9911/10000 (99%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.001135\n",
            "Train Epoch: 6 [16384/60000 (27%)]\tLoss: 0.001067\n",
            "Train Epoch: 6 [32768/60000 (55%)]\tLoss: 0.001842\n",
            "Train Epoch: 6 [49152/60000 (82%)]\tLoss: 0.000761\n",
            "\n",
            "Test set: Average loss: 0.0082, Accuracy: 9926/10000 (99%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.000684\n",
            "Train Epoch: 7 [16384/60000 (27%)]\tLoss: 0.000612\n",
            "Train Epoch: 7 [32768/60000 (55%)]\tLoss: 0.001265\n",
            "Train Epoch: 7 [49152/60000 (82%)]\tLoss: 0.001119\n",
            "\n",
            "Test set: Average loss: 0.0094, Accuracy: 9928/10000 (99%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.001055\n",
            "Train Epoch: 8 [16384/60000 (27%)]\tLoss: 0.000567\n",
            "Train Epoch: 8 [32768/60000 (55%)]\tLoss: 0.000730\n",
            "Train Epoch: 8 [49152/60000 (82%)]\tLoss: 0.000738\n",
            "\n",
            "Test set: Average loss: 0.0078, Accuracy: 9937/10000 (99%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.002358\n",
            "Train Epoch: 9 [16384/60000 (27%)]\tLoss: 0.000934\n",
            "Train Epoch: 9 [32768/60000 (55%)]\tLoss: 0.001198\n",
            "Train Epoch: 9 [49152/60000 (82%)]\tLoss: 0.000585\n",
            "\n",
            "Test set: Average loss: 0.0071, Accuracy: 9945/10000 (99%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.000501\n",
            "Train Epoch: 10 [16384/60000 (27%)]\tLoss: 0.000790\n",
            "Train Epoch: 10 [32768/60000 (55%)]\tLoss: 0.000600\n",
            "Train Epoch: 10 [49152/60000 (82%)]\tLoss: 0.002145\n",
            "\n",
            "Test set: Average loss: 0.0081, Accuracy: 9944/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmXXxVKQrTFa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "5a3851ae-f8e8-4c8b-a374-1b6b2696377e"
      },
      "source": [
        "#Train Loss\n",
        "plt.figure()\n",
        "plt.title('Train Loss')\n",
        "plt.plot(loss_train)\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "#Test Loss\n",
        "#Plot results\n",
        "plt.figure()\n",
        "plt.title('Test Loss')\n",
        "plt.plot(loss_test)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxETBISIiMfk/Fa3GssS/dE8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebgg_FOVLl5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}